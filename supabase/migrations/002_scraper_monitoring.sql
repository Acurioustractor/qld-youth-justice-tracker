-- Scraper Monitoring System Schema
-- This migration adds comprehensive monitoring capabilities for all scrapers

-- Enum for scraper status
CREATE TYPE scraper_status AS ENUM ('healthy', 'warning', 'error', 'disabled');

-- Enum for data source types
CREATE TYPE data_source AS ENUM ('parliament_hansard', 'parliament_committees', 'parliament_qon', 'treasury_budget', 'budget_website', 'youth_statistics', 'court_data', 'police_data');

-- Scraper health monitoring table
CREATE TABLE IF NOT EXISTS scraper_health (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    scraper_name TEXT NOT NULL,
    data_source data_source NOT NULL,
    status scraper_status DEFAULT 'healthy',
    last_run_at TIMESTAMP WITH TIME ZONE,
    last_success_at TIMESTAMP WITH TIME ZONE,
    next_scheduled_run TIMESTAMP WITH TIME ZONE,
    records_scraped INTEGER DEFAULT 0,
    error_count INTEGER DEFAULT 0,
    consecutive_failures INTEGER DEFAULT 0,
    average_runtime_seconds NUMERIC(10,2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    UNIQUE(scraper_name, data_source)
);

-- Scraper run logs
CREATE TABLE IF NOT EXISTS scraper_runs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    scraper_name TEXT NOT NULL,
    data_source data_source NOT NULL,
    status TEXT CHECK (status IN ('started', 'completed', 'failed', 'timeout')),
    started_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    completed_at TIMESTAMP WITH TIME ZONE,
    runtime_seconds NUMERIC(10,2),
    records_found INTEGER DEFAULT 0,
    records_processed INTEGER DEFAULT 0,
    records_inserted INTEGER DEFAULT 0,
    records_updated INTEGER DEFAULT 0,
    error_message TEXT,
    error_stack TEXT,
    warnings JSONB DEFAULT '[]'::jsonb,
    metadata JSONB DEFAULT '{}'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- Data quality metrics
CREATE TABLE IF NOT EXISTS data_quality_metrics (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    data_source data_source NOT NULL,
    metric_date DATE NOT NULL,
    completeness_score NUMERIC(5,2) CHECK (completeness_score >= 0 AND completeness_score <= 100),
    validation_pass_rate NUMERIC(5,2) CHECK (validation_pass_rate >= 0 AND validation_pass_rate <= 100),
    missing_fields JSONB DEFAULT '[]'::jsonb,
    validation_failures JSONB DEFAULT '[]'::jsonb,
    anomalies_detected JSONB DEFAULT '[]'::jsonb,
    record_count INTEGER DEFAULT 0,
    expected_record_count INTEGER,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    UNIQUE(data_source, metric_date)
);

-- Data validation rules
CREATE TABLE IF NOT EXISTS data_validation_rules (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    data_source data_source NOT NULL,
    rule_name TEXT NOT NULL,
    rule_type TEXT CHECK (rule_type IN ('required_field', 'format', 'range', 'reference', 'custom')),
    field_name TEXT,
    validation_logic JSONB NOT NULL,
    error_message TEXT,
    severity TEXT CHECK (severity IN ('error', 'warning', 'info')) DEFAULT 'error',
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- Scraper alerts
CREATE TABLE IF NOT EXISTS scraper_alerts (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    scraper_name TEXT NOT NULL,
    data_source data_source NOT NULL,
    alert_type TEXT CHECK (alert_type IN ('failure', 'data_quality', 'performance', 'anomaly', 'missing_data')),
    severity TEXT CHECK (severity IN ('critical', 'high', 'medium', 'low')) DEFAULT 'medium',
    message TEXT NOT NULL,
    details JSONB DEFAULT '{}'::jsonb,
    is_resolved BOOLEAN DEFAULT false,
    resolved_at TIMESTAMP WITH TIME ZONE,
    resolved_by TEXT,
    alert_sent BOOLEAN DEFAULT false,
    alert_sent_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- HTML selector alternatives for self-healing
CREATE TABLE IF NOT EXISTS selector_alternatives (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    scraper_name TEXT NOT NULL,
    data_source data_source NOT NULL,
    field_name TEXT NOT NULL,
    primary_selector TEXT NOT NULL,
    alternative_selectors JSONB DEFAULT '[]'::jsonb,
    xpath_alternatives JSONB DEFAULT '[]'::jsonb,
    last_working_selector TEXT,
    last_verified_at TIMESTAMP WITH TIME ZONE,
    failure_count INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    UNIQUE(scraper_name, data_source, field_name)
);

-- Proxy management
CREATE TABLE IF NOT EXISTS proxy_configs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    proxy_url TEXT NOT NULL UNIQUE,
    proxy_type TEXT CHECK (proxy_type IN ('http', 'https', 'socks5')) DEFAULT 'http',
    is_active BOOLEAN DEFAULT true,
    success_count INTEGER DEFAULT 0,
    failure_count INTEGER DEFAULT 0,
    last_used_at TIMESTAMP WITH TIME ZONE,
    response_time_ms INTEGER,
    blocked_sites JSONB DEFAULT '[]'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- Rate limiting configuration
CREATE TABLE IF NOT EXISTS rate_limit_configs (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    data_source data_source NOT NULL UNIQUE,
    requests_per_minute INTEGER DEFAULT 30,
    requests_per_hour INTEGER DEFAULT 1000,
    requests_per_day INTEGER DEFAULT 10000,
    min_delay_seconds NUMERIC(5,2) DEFAULT 0.5,
    max_delay_seconds NUMERIC(5,2) DEFAULT 2.0,
    backoff_multiplier NUMERIC(3,2) DEFAULT 1.5,
    max_retries INTEGER DEFAULT 3,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL
);

-- Historical data comparison
CREATE TABLE IF NOT EXISTS data_historical_stats (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    data_source data_source NOT NULL,
    metric_name TEXT NOT NULL,
    metric_date DATE NOT NULL,
    metric_value NUMERIC,
    metric_count INTEGER,
    percentage_change NUMERIC(10,2),
    is_anomaly BOOLEAN DEFAULT false,
    anomaly_score NUMERIC(5,2),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT TIMEZONE('utc'::text, NOW()) NOT NULL,
    UNIQUE(data_source, metric_name, metric_date)
);

-- Create indexes for performance
CREATE INDEX idx_scraper_health_status ON scraper_health(status);
CREATE INDEX idx_scraper_health_last_run ON scraper_health(last_run_at DESC);
CREATE INDEX idx_scraper_runs_scraper ON scraper_runs(scraper_name, data_source, started_at DESC);
CREATE INDEX idx_scraper_runs_status ON scraper_runs(status);
CREATE INDEX idx_data_quality_date ON data_quality_metrics(metric_date DESC);
CREATE INDEX idx_data_quality_source ON data_quality_metrics(data_source);
CREATE INDEX idx_alerts_unresolved ON scraper_alerts(is_resolved, created_at DESC) WHERE is_resolved = false;
CREATE INDEX idx_historical_anomalies ON data_historical_stats(is_anomaly, metric_date DESC) WHERE is_anomaly = true;

-- Create update timestamp trigger function
CREATE OR REPLACE FUNCTION trigger_set_timestamp()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = TIMEZONE('utc'::text, NOW());
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Add update triggers
CREATE TRIGGER set_timestamp_scraper_health
BEFORE UPDATE ON scraper_health
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_data_quality_metrics
BEFORE UPDATE ON data_quality_metrics
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_data_validation_rules
BEFORE UPDATE ON data_validation_rules
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_selector_alternatives
BEFORE UPDATE ON selector_alternatives
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_proxy_configs
BEFORE UPDATE ON proxy_configs
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_rate_limit_configs
BEFORE UPDATE ON rate_limit_configs
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

-- Helper functions for monitoring

-- Function to calculate scraper health score
CREATE OR REPLACE FUNCTION calculate_scraper_health_score(
    p_scraper_name TEXT,
    p_data_source data_source
) RETURNS NUMERIC AS $$
DECLARE
    health_score NUMERIC := 100;
    recent_failures INTEGER;
    uptime_percentage NUMERIC;
    data_freshness_hours INTEGER;
BEGIN
    -- Get recent failure count (last 24 hours)
    SELECT COUNT(*) INTO recent_failures
    FROM scraper_runs
    WHERE scraper_name = p_scraper_name
    AND data_source = p_data_source
    AND status = 'failed'
    AND started_at > NOW() - INTERVAL '24 hours';
    
    -- Deduct points for failures
    health_score := health_score - (recent_failures * 10);
    
    -- Calculate uptime percentage (last 7 days)
    SELECT 
        CASE 
            WHEN COUNT(*) > 0 THEN 
                (COUNT(*) FILTER (WHERE status = 'completed')::NUMERIC / COUNT(*)::NUMERIC) * 100
            ELSE 100
        END INTO uptime_percentage
    FROM scraper_runs
    WHERE scraper_name = p_scraper_name
    AND data_source = p_data_source
    AND started_at > NOW() - INTERVAL '7 days';
    
    -- Adjust score based on uptime
    IF uptime_percentage < 90 THEN
        health_score := health_score - (90 - uptime_percentage);
    END IF;
    
    -- Check data freshness
    SELECT EXTRACT(EPOCH FROM (NOW() - last_success_at)) / 3600 INTO data_freshness_hours
    FROM scraper_health
    WHERE scraper_name = p_scraper_name
    AND data_source = p_data_source;
    
    -- Deduct points for stale data
    IF data_freshness_hours > 48 THEN
        health_score := health_score - 20;
    ELSIF data_freshness_hours > 24 THEN
        health_score := health_score - 10;
    END IF;
    
    -- Ensure score is between 0 and 100
    RETURN GREATEST(0, LEAST(100, health_score));
END;
$$ LANGUAGE plpgsql;

-- Function to detect anomalies in scraped data
CREATE OR REPLACE FUNCTION detect_data_anomalies(
    p_data_source data_source,
    p_metric_name TEXT,
    p_current_value NUMERIC
) RETURNS BOOLEAN AS $$
DECLARE
    avg_value NUMERIC;
    std_dev NUMERIC;
    z_score NUMERIC;
BEGIN
    -- Calculate average and standard deviation from last 30 days
    SELECT 
        AVG(metric_value),
        STDDEV(metric_value)
    INTO avg_value, std_dev
    FROM data_historical_stats
    WHERE data_source = p_data_source
    AND metric_name = p_metric_name
    AND metric_date > CURRENT_DATE - INTERVAL '30 days';
    
    -- If not enough historical data, no anomaly
    IF avg_value IS NULL OR std_dev IS NULL OR std_dev = 0 THEN
        RETURN FALSE;
    END IF;
    
    -- Calculate z-score
    z_score := ABS((p_current_value - avg_value) / std_dev);
    
    -- Flag as anomaly if z-score > 3 (99.7% confidence interval)
    RETURN z_score > 3;
END;
$$ LANGUAGE plpgsql;

-- Row Level Security
ALTER TABLE scraper_health ENABLE ROW LEVEL SECURITY;
ALTER TABLE scraper_runs ENABLE ROW LEVEL SECURITY;
ALTER TABLE data_quality_metrics ENABLE ROW LEVEL SECURITY;
ALTER TABLE data_validation_rules ENABLE ROW LEVEL SECURITY;
ALTER TABLE scraper_alerts ENABLE ROW LEVEL SECURITY;
ALTER TABLE selector_alternatives ENABLE ROW LEVEL SECURITY;
ALTER TABLE proxy_configs ENABLE ROW LEVEL SECURITY;
ALTER TABLE rate_limit_configs ENABLE ROW LEVEL SECURITY;
ALTER TABLE data_historical_stats ENABLE ROW LEVEL SECURITY;

-- Create read-only policies for public access
CREATE POLICY "Allow public read access" ON scraper_health FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON scraper_runs FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON data_quality_metrics FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON data_validation_rules FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON scraper_alerts FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON selector_alternatives FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON proxy_configs FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON rate_limit_configs FOR SELECT USING (true);
CREATE POLICY "Allow public read access" ON data_historical_stats FOR SELECT USING (true);

-- Insert default rate limit configurations
INSERT INTO rate_limit_configs (data_source, requests_per_minute, requests_per_hour, min_delay_seconds, max_delay_seconds)
VALUES 
    ('parliament_hansard', 20, 500, 1.0, 3.0),
    ('parliament_committees', 20, 500, 1.0, 3.0),
    ('parliament_qon', 20, 500, 1.0, 3.0),
    ('treasury_budget', 10, 200, 2.0, 5.0),
    ('budget_website', 30, 1000, 0.5, 2.0),
    ('youth_statistics', 15, 300, 1.5, 4.0),
    ('court_data', 15, 300, 1.5, 4.0),
    ('police_data', 15, 300, 1.5, 4.0)
ON CONFLICT (data_source) DO NOTHING;